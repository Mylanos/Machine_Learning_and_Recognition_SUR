%for gndr in male female; do
%grep test2004 /mnt/matylda5/ijancik/GID/lists/train_$gndr.list | randomize | head -500 | \
%awk -F '/|\\[|,|]' '{
%  fname=gensub("-x.fea$", "",  1, $3); 
%  in_dir="/mnt/matylda2/data/NIST-SRE/2004/test/data"
%  out_dir="~/IKR3/data/'$gndr'"
%  system("sox -w -s -r 8000 "in_dir"/"fname".raw "out_dir"/"fname"_"$4"_"$5".raw trim "$4*80"s "($5-$4+1)*80"s") 
%}'
%done


%Read all the training and test data into cell-arrays 

train_m = raw8khz2mfcc('data/male/train');
train_f = raw8khz2mfcc('data/female/train');
[test_m files_m] = raw8khz2mfcc('data/male/test');
[test_f files_f] = raw8khz2mfcc('data/female/test');


% For training, wi do not need to know which frame come from which training
% segment. So, for each gender, concatenate all the training feature
% matrices into single matrix

train_m=cell2mat(train_m);
train_f=cell2mat(train_f);


% PCA reduction to 2 dimensions
cov_tot = cov([train_m; train_f], 1)
[e,d]=eigs(cov_tot, 2);
plot(train_m * e * [1;j], 'b.', 'MarkerSize', 1); hold on
plot(train_f * e * [1;j], 'r.', 'MarkerSize', 1)


% LDA reduction to 1 dimenzion (only one LDA dimension is available for 2 tridy)

n_m = size(train_m,1);
n_f = size(train_f,1);
cov_wc = (n_m*cov(train_m, 1) + n_f*cov(train_f, 1)) / (n_m + n_f);
cov_ac = cov_tot - cov_wc;
[e,d]=eigs(cov_ac, cov_wc, 1)
[hist_m x_m] = hist(train_m * e, 40);
[hist_f x_f] = hist(train_f * e, 40);
plot(x_m, hist_m, 'b', x_f, hist_f, 'r');


% For one male test utterance (test_m{1}), obtain frame-by-frame likelihoods
% with two models, one trained using male and second using feamle training data.
% In this case, the models are single gaussians with diagonal covariance matrices.

l_m = gaus(test_m{1}, mean(train_m), var(train_m, 1));
l_f = gaus(test_m{1}, mean(train_f), var(train_f, 1));

% Plot the frame-by-frame likelihoods obtained with the two models
figure; plot(l_m, 'b'); hold on; plot(l_f, 'r');

% Plot frame-by-frame posteriors
figure; plot(l_m./(l_m+l_f), 'b'); hold on; plot(l_f./(l_m+l_f), 'r');


% Plot frame-by-frame log-likelihoods
figure; plot(log(l_m), 'b'); hold on; plot(log(l_f), 'r');

% But, we do not want to make frame-by-frame decisions. We want to recognize the
% whole segment. Aplying frame independeny assumption, we sum log-likelihoods.
% Assuming equal priors, we decide for class 'male' if the following
% log-likelihood ratio is positive.
sum(log(l_m))-sum(log(l_f))


% Repeating the whole excercise, now with gaussian models with full covariance
% matrices

l_m = gaus(test_m{1}, mean(train_m), cov(train_m, 1));
l_f = gaus(test_m{1}, mean(train_f), cov(train_f, 1));
figure; plot(l_m./(l_m+l_f), 'b'); hold on; plot(l_f./(l_m+l_f), 'r');
figure; plot(log(l_m), 'b'); hold on; plot(log(l_f), 'r');
sum(log(l_m))-sum(log(l_f))


% Again gaussian models with full covariance matrices. Now testing a female
% utterance

l_m = gaus(test_f{1}, mean(train_m), cov(train_m, 1));
l_f = gaus(test_f{1}, mean(train_f), cov(train_f, 1));
figure; plot(l_m./(l_m+l_f), 'b'); hold on; plot(l_f./(l_m+l_f), 'r');
figure; plot(log(l_m), 'b'); hold on; plot(log(l_f), 'r');
sum(log(l_m))-sum(log(l_f))


% Now run recognition for all male test utterances
% To do the same for females set "test_set=test_f"

mean_m = mean(train_m);
cov_m  = cov(train_m, 1);
mean_f = mean(train_f);
cov_f  = cov(train_f, 1);

test_set = test_m;
for ii=1:length(test_set)
  l_m = gaus(test_set{ii}, mean_m, cov_m);
  l_f = gaus(test_set{ii}, mean_f, cov_f);
  score(ii)=sum(log(l_m))-sum(log(l_f));
end
score


% Run recognition with 1-dimensional LDA projected data

mean_m = mean(train_m * e);
var_m  = var(train_m * e, 1);
mean_f = mean(train_f * e);
var_f  = var(train_f * e, 1);

test_set=test_m;
for ii=1:length(test_set)
  l_m = gaus(test_set{ii} * e, mean_m, var_m);
  l_f = gaus(test_set{ii} * e, mean_f, var_f);
  score(ii)=sum(log(l_m))-sum(log(l_f));
end
score


% Train and test with GMM models with diagonal covariance matrices

WW_m = [1]
MM_m = [mean(train_m)']
EE_m = [var(train_m, 1)']

% Repeat each of the two following lines desirable times. 
% Function 'split_mix' doubles the number of gaussian components
% Function 'dgmixtrain' updates GMM parameters using single EM iteration
[WW_m, MM_m, EE_m] = split_mix(WW_m, MM_m, EE_m)
[WW_m, MM_m, EE_m] = dgmixtrain(train_m', WW_m, MM_m, EE_m)

WW_f = [1]
MM_f = [mean(train_f)']
EE_f = [var(train_f, 1)']
[WW_f, MM_f, EE_f] = split_mix(WW_f, MM_f, EE_f)
[WW_f, MM_f, EE_f] = dgmixtrain(train_f', WW_f, MM_f, EE_f)


test_set=test_m;
for ii=1:length(test_set)
  l_m = gmm_pdf(test_set{ii}', WW_m, MM_m, EE_m);
  l_f = gmm_pdf(test_set{ii}', WW_f, MM_f, EE_f);
  score(ii)=sum(log(l_m))-sum(log(l_f));
end
score
